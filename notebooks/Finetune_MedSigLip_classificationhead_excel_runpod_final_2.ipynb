{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFU3B09TKuQf"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Sgv3DCPIA5p-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --quiet transformers torchvision bitsandbytes datasets evaluate peft trl scikit-learn Pillow ipywidgets jupyterlab_widgets tensorboard sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXh0RtBk_Xc6"
   },
   "source": [
    "## Load model from Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r-esHCwnQFye"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6c7c5c05ca4475838674e397915c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/879 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619e718352394a4aa9cccd106418429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76115be8394448c68bf83da4e29409c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/360 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a47f97101524cdfbde6e9f3c124b933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/809 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9273fd1aa9a14485a1642a13d1d3171d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edd1aae176948d9840d36a3ea1938b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/455 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aafec2c7c8d24800b03a78888fdba2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import torch.nn as nn\n",
    "from transformers import SiglipModel\n",
    "\n",
    "model_id = \"google/medsiglip-448\"\n",
    "\n",
    "class SiglipForClassification(nn.Module):\n",
    "    def __init__(self, siglip_model, num_classes=1):  # num_classes=1 for binary classification\n",
    "        super().__init__()\n",
    "        self.siglip = siglip_model\n",
    "        self.classifier = nn.Linear(siglip_model.config.vision_config.hidden_size, num_classes)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits\n",
    "        \n",
    "    def forward(self, pixel_values, labels=None, **kwargs):\n",
    "        # Get vision embeddings\n",
    "        vision_outputs = self.siglip.vision_model(pixel_values=pixel_values)\n",
    "        pooled_output = vision_outputs.pooler_output\n",
    "        \n",
    "        # Get logits (single output for binary classification)\n",
    "        logits = self.classifier(pooled_output)  # Shape: [batch_size, 1]\n",
    "        \n",
    "        # Compute loss if labels are provided\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Ensure labels are float and have shape [batch_size, 1]\n",
    "            labels = labels.view(-1, 1).float()  # Reshape and convert to float\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "        \n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"logits\": logits\n",
    "        }\n",
    "\n",
    "# Load base SigLIP model\n",
    "base_model = SiglipModel.from_pretrained(model_id)\n",
    "model = SiglipForClassification(base_model, num_classes=1)  # Binary classification\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrnDCZvvzWtS"
   },
   "source": [
    "## Prepare fine-tuning dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTYiM4RAjJAo"
   },
   "source": [
    "Load the data using the Hugging Face `datasets` library. Then, create train and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331ac214490a4487b458b07e82a46516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Appendicitis_vs_normal.zip:   0%|          | 0.00/1.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Image\n",
    "\n",
    "\n",
    "# 1. Download and Unzip the data from Hub\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# === DOWNLOAD ZIP FILE FROM HUGGING FACE DATASET REPO ===\n",
    "repo_id = \"IraBid-Medical-AI/Appendicitis_vs_normal_classification\"\n",
    "filename = \"Appendicitis_vs_normal.zip\"\n",
    "\n",
    "# Download the ZIP to local cache\n",
    "zip_path = hf_hub_download(\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"dataset\",\n",
    "    filename=filename,\n",
    "    revision=\"main\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: Extracted to Appendicitis_vs_normal\n"
     ]
    }
   ],
   "source": [
    "# === UNZIP TO TARGET FOLDER ===\n",
    "extract_dir = \"Appendicitis_vs_normal\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"✅ Done: Extracted to {extract_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IPZPx2cxCzxx",
    "outputId": "bd079de6-085b-43ef-85e3-e87cc2255288"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f947dac06d504504a5a1735b137f45be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624a3606e4674aa6b52db91a195d23d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/30450 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bd2fce90f745a6908b053e87254054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing checksums:  19%|#9        | 5821/30450 [00:05<00:21, 1164.17it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead862f90f004e7e88ddadb927776f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3718a5067c446d5bb401097840621de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/7630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50908d2c2aab42a9847ebe0b44cfd09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/7630 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038e9512bc874bddba4c1a4d79c7c4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e434cd023b9439394f7fe9fead7680e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/9590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17a3c36914545a1bec2cd76e0128a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/9590 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66057085be64c458de94378dd186bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing checksums:  67%|######7   | 6470/9590 [00:05<00:02, 1293.95it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a78e812ae98146d39ac0d9a804f26241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 30450\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 7630\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 9590\n",
      "    })\n",
      "})\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 2. Load dataset\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Path to the extracted dataset folder\n",
    "data_dir = r\"./Appendicitis_vs_normal/Appendicitis_vs_normal\"  # UPDATE this path\n",
    "\n",
    "# Define paths for each split\n",
    "train_dir = f\"{data_dir}/Training_data_png\"\n",
    "val_dir   = f\"{data_dir}/Validation_data_png\"\n",
    "test_dir  = f\"{data_dir}/Test_data_png\"\n",
    "\n",
    "# Load splits using 'imagefolder' format\n",
    "train_ds = load_dataset(\"imagefolder\", data_dir=train_dir, split=\"train\")\n",
    "val_ds   = load_dataset(\"imagefolder\", data_dir=val_dir, split=\"train\")\n",
    "test_ds  = load_dataset(\"imagefolder\", data_dir=test_dir, split=\"train\")\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "data = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"validation\": val_ds,\n",
    "    \"test\": test_ds,\n",
    "})\n",
    "\n",
    "print(data)\n",
    "\n",
    "# 3. Peek at a sample\n",
    "data[\"train\"][0][\"image\"]\n",
    "# Display the corresponding label\n",
    "print(data[\"train\"][0][\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V03H6cfnofY_"
   },
   "source": [
    "Inspect a sample data point, which contains:\n",
    "\n",
    "* `image`: image patch as a `PIL` image object\n",
    "* `label`: integer class label corresponding to tissue type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7420ca04dd484855a872e6516ddb30f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38cf3633d044ed49674c5f8dcf4df3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a6240859354294985ec58ca15c7660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# adding 'path' column to each dataset\n",
    "\n",
    "def add_path(example, root_dir):\n",
    "    # The 'image' field is a PIL Image, but the dataset from 'imagefolder' also\n",
    "    # includes the 'image' feature with 'path' attribute for each image.\n",
    "    # However, if not present, reconstruct the path from root_dir and label info.\n",
    "    \n",
    "    # Huggingface's imagefolder loader often provides 'path' in 'image' feature metadata,\n",
    "    # So we can try to get it directly:\n",
    "    try:\n",
    "        image_path = example[\"image\"].filename\n",
    "    except AttributeError:\n",
    "        # fallback: try reconstructing (if you know directory structure and filenames)\n",
    "        image_path = None\n",
    "\n",
    "    # If for some reason filename is missing, you can create path from label + file name if available,\n",
    "    # but usually filename should be in the 'image' object.\n",
    "    \n",
    "    return {\"path\": image_path}\n",
    "\n",
    "# Add path column using map for all datasets:\n",
    "train_ds = train_ds.map(lambda x: add_path(x, train_dir))\n",
    "val_ds = val_ds.map(lambda x: add_path(x, val_dir))\n",
    "test_ds = test_ds.map(lambda x: add_path(x, test_dir))\n",
    "\n",
    "# Update the dataset dict\n",
    "data = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"validation\": val_ds,\n",
    "    \"test\": test_ds,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': Image(mode=None, decode=True), 'label': ClassLabel(names=['negative', 'positive']), 'path': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "print(data[\"train\"].features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "c6EduPmWC4fO",
    "outputId": "1a81aa27-b3df-46cd-b23d-b62a152df041"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/MedGemma/notebooks/Appendicitis_vs_normal/Appendicitis_vs_normal/Training_data_png/negative/0006_0006_slice_007.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][287][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][287][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tKufzKE_C7Vt",
    "outputId": "877f2305-48d2-4a18-c693-22db671acf6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][287][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHOtCBFfSWyS"
   },
   "source": [
    "## Fine-tune the model\n",
    "\n",
    "Contrastive image-text learning is a method that trains models to learn the relationship between images and text, such that the representations of matching image-text pairs are brought closer together in a shared embedding space while non-matching pairs are pushed further apart.\n",
    "\n",
    "This notebook demonstrates contrastive fine-tuning of MedSigLIP, where the vision and text encoders are jointly trained on image and text data, using the `Trainer` from the Hugging Face `Transformers` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrDwrz6iD3Yl"
   },
   "source": [
    "Define a data collator to prepare batches of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    images = [example[\"image\"] for example in examples]\n",
    "    labels = [example[\"label\"] for example in examples]\n",
    "    paths = [example[\"path\"] for example in examples]  # add paths here\n",
    "    \n",
    "     # Process images\n",
    "    batch = processor(images=images, return_tensors=\"pt\")\n",
    "    \n",
    "    # add labels and paths to the batch\n",
    "    batch[\"labels\"] = torch.tensor(labels, dtype=torch.float).view(-1, 1)\n",
    "    batch[\"path\"] = paths  # return paths as is (list of strings)\n",
    "    \n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "QRPETOTGV81b"
   },
   "outputs": [],
   "source": [
    "#import torch\n",
    "\n",
    "\n",
    "#def collate_fn(examples):\n",
    "    # Extract images and labels\n",
    "#    images = [example[\"image\"] for example in examples]\n",
    "#    labels = [example[\"label\"] for example in examples]\n",
    "    \n",
    "    # Process images\n",
    "#    batch = processor(images=images, return_tensors=\"pt\")\n",
    "    \n",
    "    # Add labels\n",
    "#    batch[\"labels\"] = torch.tensor(labels, dtype=torch.float).view(-1, 1)\n",
    "    \n",
    "#    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fsaon7JoBq5H"
   },
   "source": [
    "Configure training parameters in [`TrainingArguments`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "E6W_gQmfRXWx"
   },
   "outputs": [],
   "source": [
    "num_train_epochs = 2  # @param {type: \"number\"}\n",
    "learning_rate = 1e-4  # @param {type: \"number\"}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"medsiglip-appendicits-binary\",  # Directory and Hub repository id to save the model to\n",
    "    num_train_epochs=num_train_epochs,      # Number of training epochs\n",
    "    per_device_train_batch_size=16,         # Batch size per device during training\n",
    "    per_device_eval_batch_size=16,          # Batch size per device during evaluation\n",
    "    gradient_accumulation_steps=2,          # Number of steps before performing a backward/update pass\n",
    "    logging_steps=50,                       # Number of steps between logs\n",
    "    save_strategy=\"steps\",                  # Save checkpoint every eval_steps\n",
    "    save_steps=100,                          # Save every 50 steps (same as eval_steps)\n",
    "    eval_strategy=\"steps\",                  # Evaluate every `eval_steps`\n",
    "    eval_steps=100,                          # Number of steps between evaluations\n",
    "    learning_rate=learning_rate,            # Learning rate\n",
    "    weight_decay=0.01,                      # Much stronger weight decay\n",
    "    warmup_steps=100,                        # Number of steps for linear warmup from 0 to learning rate\n",
    "    lr_scheduler_type=\"cosine\", \n",
    "    dataloader_drop_last=True,              # Consistent batch sizes\n",
    "    max_grad_norm=0.5,\n",
    "    push_to_hub=True,        \n",
    "    remove_unused_columns=False,            # Push model to Hub\n",
    "    report_to=\"tensorboard\",                # Report metrics to tensorboard\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the metrics\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "roc_auc_metric = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute metrics for binary classification (normal vs. positive).\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred  # predictions: [batch_size, 1], labels: [batch_size]\n",
    "    \n",
    "    # Convert logits to probabilities and predictions\n",
    "    probabilities = 1 / (1 + np.exp(-predictions))  # Sigmoid: [batch_size, 1]\n",
    "    pred_classes = (probabilities > 0.5).astype(np.int32).flatten()  # Threshold at 0.5: [batch_size]\n",
    "    \n",
    "    # Ensure labels are integers\n",
    "    labels = labels.astype(np.int32)\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {}\n",
    "    metrics.update(accuracy_metric.compute(\n",
    "        predictions=pred_classes,\n",
    "        references=labels,\n",
    "    ))\n",
    "    metrics.update(f1_metric.compute(\n",
    "        predictions=pred_classes,\n",
    "        references=labels,\n",
    "        average =\"macro\"\n",
    "    ))\n",
    "    # Compute ROC-AUC using positive class probabilities\n",
    "    try:\n",
    "        auc = roc_auc_metric.compute(\n",
    "            prediction_scores=probabilities.flatten(),  # Positive class probabilities\n",
    "            references=labels,\n",
    "            average=\"macro\"  # Binary classification uses macro for consistency\n",
    "        )\n",
    "        metrics.update({\"auc\": auc[\"roc_auc\"]})\n",
    "    except Exception as e:\n",
    "        metrics.update({\"auc\": None, \"auc_error\": str(e)})\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1rMdSj1Tj1K"
   },
   "source": [
    "Construct a [`Trainer`](https://huggingface.co/docs/transformers/trainer) using the previously defined training parameters and data collator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "dWcynpm0MHDc"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"validation\"].shuffle().select(range(100)),  # Use subset of validation set for faster run\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoHlpSKKVbDb"
   },
   "source": [
    "Launch the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZcOXgddDSRd",
    "outputId": "c31b7685-4f44-4be7-af97-d41778f43736"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='1904' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  30/1904 03:08 < 3:30:40, 0.15 it/s, Epoch 0.03/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf9QkPFAfegp"
   },
   "source": [
    "## Evaluate the fine-tuned model on a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 435\n",
      "Evaluating model on train dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 14/14 [00:32<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Overall Accuracy: 0.7333\n",
      "Weighted F1-Score: 0.7003\n",
      "Macro F1-Score: 0.6428\n",
      "\n",
      "Per-Class Metrics:\n",
      "----------------------------------------------------------------------\n",
      "Class           Precision    Recall       F1-Score     Support   \n",
      "----------------------------------------------------------------------\n",
      "normal          0.7330       0.9373       0.8226       287       \n",
      "appendicitis    0.7353       0.3378       0.4630       148       \n",
      "----------------------------------------------------------------------\n",
      "Weighted Avg    0.7338       0.7333       0.7003       435       \n",
      "Macro Avg       0.7341       0.6376       0.6428       435       \n",
      "\n",
      "Detailed Classification Report:\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal     0.7330    0.9373    0.8226       287\n",
      "appendicitis     0.7353    0.3378    0.4630       148\n",
      "\n",
      "    accuracy                         0.7333       435\n",
      "   macro avg     0.7341    0.6376    0.6428       435\n",
      "weighted avg     0.7338    0.7333    0.7003       435\n",
      "\n",
      "✅ Results saved to train_predictions.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, train_dataset, processor, batch_size=32, device='cuda'):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the fine-tuned model on train data\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "    all_paths = []\n",
    "    print(\"Evaluating model on train dataset...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Testing\")):\n",
    "            if 'pixel_values' not in batch or 'labels' not in batch:\n",
    "                raise ValueError(\"Batch missing required keys: 'pixel_values' or 'labels'.\")\n",
    "            pixel_values = batch['pixel_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            paths = batch['path']\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            logits = outputs['logits']\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            predictions = (probabilities > 0.4).long().view(-1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_logits.extend(probabilities.cpu().numpy().flatten())  # Save probabilities\n",
    "            all_paths.extend(paths)\n",
    "    return np.array(all_predictions), np.array(all_labels), np.array(all_logits), all_paths\n",
    "\n",
    "\n",
    "def compute_detailed_metrics(predictions, labels, class_names):\n",
    "    \"\"\"\n",
    "    Compute detailed evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        labels, predictions, average=None\n",
    "    )\n",
    "    \n",
    "    # Weighted averages\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Macro averages\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='macro'\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Per-class metrics\n",
    "    print(\"Per-Class Metrics:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name:<15} {precision[i]:<12.4f} {recall[i]:<12.4f} {f1[i]:<12.4f} {support[i]:<10}\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Weighted Avg':<15} {precision_weighted:<12.4f} {recall_weighted:<12.4f} {f1_weighted:<12.4f} {sum(support):<10}\")\n",
    "    print(f\"{'Macro Avg':<15} {precision_macro:<12.4f} {recall_macro:<12.4f} {f1_macro:<12.4f} {sum(support):<10}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'per_class_precision': precision,\n",
    "        'per_class_recall': recall,\n",
    "        'per_class_f1': f1,\n",
    "        'support': support\n",
    "    }\n",
    "\n",
    "\n",
    "def run_evaluation():\n",
    "    ABDOMINAL_PAIN_CLASSES = ['normal', 'appendicitis']\n",
    "    train_data = data[\"train\"]\n",
    "    print(f\"Train dataset size: {len(train_data)}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    predictions, labels, probabilities, paths = evaluate_model(\n",
    "        model, \n",
    "        train_data, \n",
    "        processor, \n",
    "        batch_size=32, \n",
    "        device=device\n",
    "    )\n",
    "    metrics = compute_detailed_metrics(predictions, labels, ABDOMINAL_PAIN_CLASSES)\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(\n",
    "        labels, \n",
    "        predictions, \n",
    "        target_names=ABDOMINAL_PAIN_CLASSES,\n",
    "        digits=4\n",
    "    ))\n",
    "    # Save results to Excel\n",
    "    df_results = pd.DataFrame({\n",
    "        \"image_path\": paths,\n",
    "        \"probability\": probabilities,\n",
    "        \"actual_label\": labels.flatten(),\n",
    "        \"prediction\": predictions.flatten()\n",
    "    })\n",
    "    df_results.to_excel(\"train_predictions.xlsx\", index=False)\n",
    "    print(\"✅ Results saved to train_predictions.xlsx\")\n",
    "    return metrics, predictions, labels, probabilities, paths\n",
    "\n",
    "# Run the evaluation\n",
    "evaluation_results = run_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, valid_dataset, processor, batch_size=32, device='cuda'):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the fine-tuned model on valid data\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "    all_paths = []\n",
    "    print(\"Evaluating model on valid dataset...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(valid_loader, desc=\"Testing\")):\n",
    "            if 'pixel_values' not in batch or 'labels' not in batch:\n",
    "                raise ValueError(\"Batch missing required keys: 'pixel_values' or 'labels'.\")\n",
    "            pixel_values = batch['pixel_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            paths = batch['path']\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            logits = outputs['logits']\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            predictions = (probabilities > 0.4).long().view(-1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_logits.extend(probabilities.cpu().numpy().flatten())  # Save probabilities\n",
    "            all_paths.extend(paths)\n",
    "    return np.array(all_predictions), np.array(all_labels), np.array(all_logits), all_paths\n",
    "\n",
    "\n",
    "def compute_detailed_metrics(predictions, labels, class_names):\n",
    "    \"\"\"\n",
    "    Compute detailed evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        labels, predictions, average=None\n",
    "    )\n",
    "    \n",
    "    # Weighted averages\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Macro averages\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='macro'\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Per-class metrics\n",
    "    print(\"Per-Class Metrics:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name:<15} {precision[i]:<12.4f} {recall[i]:<12.4f} {f1[i]:<12.4f} {support[i]:<10}\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Weighted Avg':<15} {precision_weighted:<12.4f} {recall_weighted:<12.4f} {f1_weighted:<12.4f} {sum(support):<10}\")\n",
    "    print(f\"{'Macro Avg':<15} {precision_macro:<12.4f} {recall_macro:<12.4f} {f1_macro:<12.4f} {sum(support):<10}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'per_class_precision': precision,\n",
    "        'per_class_recall': recall,\n",
    "        'per_class_f1': f1,\n",
    "        'support': support\n",
    "    }\n",
    "\n",
    "\n",
    "def run_evaluation():\n",
    "    ABDOMINAL_PAIN_CLASSES = ['normal', 'appendicitis']\n",
    "    valid_data = data[\"valid\"]\n",
    "    print(f\"Validati dataset size: {len(valid_data)}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    predictions, labels, probabilities, paths = evaluate_model(\n",
    "        model, \n",
    "        test_data, \n",
    "        processor, \n",
    "        batch_size=32, \n",
    "        device=device\n",
    "    )\n",
    "    metrics = compute_detailed_metrics(predictions, labels, ABDOMINAL_PAIN_CLASSES)\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(\n",
    "        labels, \n",
    "        predictions, \n",
    "        target_names=ABDOMINAL_PAIN_CLASSES,\n",
    "        digits=4\n",
    "    ))\n",
    "    # Save results to Excel\n",
    "    df_results = pd.DataFrame({\n",
    "        \"image_path\": paths,\n",
    "        \"probability\": probabilities,\n",
    "        \"actual_label\": labels.flatten(),\n",
    "        \"prediction\": predictions.flatten()\n",
    "    })\n",
    "    df_results.to_excel(\"test_predictions.xlsx\", index=False)\n",
    "    print(\"✅ Results saved to test_predictions.xlsx\")\n",
    "    return metrics, predictions, labels, probabilities, paths\n",
    "\n",
    "# Run the evaluation\n",
    "evaluation_results = run_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 137\n",
      "Evaluating model on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 5/5 [00:10<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EVALUATION RESULTS\n",
      "==================================================\n",
      "Overall Accuracy: 0.6350\n",
      "Weighted F1-Score: 0.5716\n",
      "Macro F1-Score: 0.4903\n",
      "\n",
      "Per-Class Metrics:\n",
      "----------------------------------------------------------------------\n",
      "Class           Precision    Recall       F1-Score     Support   \n",
      "----------------------------------------------------------------------\n",
      "normal          0.6612       0.8989       0.7619       89        \n",
      "appendicitis    0.4375       0.1458       0.2188       48        \n",
      "----------------------------------------------------------------------\n",
      "Weighted Avg    0.5828       0.6350       0.5716       137       \n",
      "Macro Avg       0.5493       0.5224       0.4903       137       \n",
      "\n",
      "Detailed Classification Report:\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal     0.6612    0.8989    0.7619        89\n",
      "appendicitis     0.4375    0.1458    0.2188        48\n",
      "\n",
      "    accuracy                         0.6350       137\n",
      "   macro avg     0.5493    0.5224    0.4903       137\n",
      "weighted avg     0.5828    0.6350    0.5716       137\n",
      "\n",
      "✅ Results saved to test_predictions.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, test_dataset, processor, batch_size=32, device='cuda'):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the fine-tuned model on test data\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "    all_paths = []\n",
    "    print(\"Evaluating model on test dataset...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"Testing\")):\n",
    "            if 'pixel_values' not in batch or 'labels' not in batch:\n",
    "                raise ValueError(\"Batch missing required keys: 'pixel_values' or 'labels'.\")\n",
    "            pixel_values = batch['pixel_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            paths = batch['path']\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            logits = outputs['logits']\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            predictions = (probabilities > 0.4).long().view(-1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_logits.extend(probabilities.cpu().numpy().flatten())  # Save probabilities\n",
    "            all_paths.extend(paths)\n",
    "    return np.array(all_predictions), np.array(all_labels), np.array(all_logits), all_paths\n",
    "\n",
    "\n",
    "def compute_detailed_metrics(predictions, labels, class_names):\n",
    "    \"\"\"\n",
    "    Compute detailed evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        labels, predictions, average=None\n",
    "    )\n",
    "    \n",
    "    # Weighted averages\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    \n",
    "    # Macro averages\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='macro'\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted F1-Score: {f1_weighted:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "    print()\n",
    "    \n",
    "    # Per-class metrics\n",
    "    print(\"Per-Class Metrics:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name:<15} {precision[i]:<12.4f} {recall[i]:<12.4f} {f1[i]:<12.4f} {support[i]:<10}\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Weighted Avg':<15} {precision_weighted:<12.4f} {recall_weighted:<12.4f} {f1_weighted:<12.4f} {sum(support):<10}\")\n",
    "    print(f\"{'Macro Avg':<15} {precision_macro:<12.4f} {recall_macro:<12.4f} {f1_macro:<12.4f} {sum(support):<10}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'per_class_precision': precision,\n",
    "        'per_class_recall': recall,\n",
    "        'per_class_f1': f1,\n",
    "        'support': support\n",
    "    }\n",
    "\n",
    "\n",
    "def run_evaluation():\n",
    "    ABDOMINAL_PAIN_CLASSES = ['normal', 'appendicitis']\n",
    "    test_data = data[\"test\"]\n",
    "    print(f\"Test dataset size: {len(test_data)}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    predictions, labels, probabilities, paths = evaluate_model(\n",
    "        model, \n",
    "        test_data, \n",
    "        processor, \n",
    "        batch_size=32, \n",
    "        device=device\n",
    "    )\n",
    "    metrics = compute_detailed_metrics(predictions, labels, ABDOMINAL_PAIN_CLASSES)\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(\n",
    "        labels, \n",
    "        predictions, \n",
    "        target_names=ABDOMINAL_PAIN_CLASSES,\n",
    "        digits=4\n",
    "    ))\n",
    "    # Save results to Excel\n",
    "    df_results = pd.DataFrame({\n",
    "        \"image_path\": paths,\n",
    "        \"probability\": probabilities,\n",
    "        \"actual_label\": labels.flatten(),\n",
    "        \"prediction\": predictions.flatten()\n",
    "    })\n",
    "    df_results.to_excel(\"test_predictions.xlsx\", index=False)\n",
    "    print(\"✅ Results saved to test_predictions.xlsx\")\n",
    "    return metrics, predictions, labels, probabilities, paths\n",
    "\n",
    "# Run the evaluation\n",
    "evaluation_results = run_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "fine_tune_with_hugging_face.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
